# keys for the as-is data-set (text files)
training_data="dataset/training.txt"
test_data="dataset/test.txt"


# keys for raw data purely strings (text files)
coarse_classes_training="common_data/raw/training/coarse_classes.txt"
fine_classes_training="common_data/raw/training/fine_classes.txt"
abbr_classes_training="common_data/raw/training/abbr_classes.txt"
desc_classes_training="common_data/raw/training/desc_classes.txt"
enty_classes_training="common_data/raw/training/enty_classes.txt"
hum_classes_training="common_data/raw/training/hum_classes.txt"
loc_classes_training="common_data/raw/training/loc_classes.txt"
num_classes_training="common_data/raw/training/num_classes.txt"
raw_sentence_training="common_data/raw/training/raw_sentence_file.txt"

coarse_classes_test="common_data/raw/test/coarse_classes.txt"
fine_classes_test="common_data/raw/test/fine_classes.txt"
raw_sentence_test="common_data/raw/test/raw_sentence_file.txt"


# keys for text annotation data (directories)
coarse_training_doc="common_data/nlp/training/coarse/doc.pickle"
coarse_training_ner="common_data/nlp/training/coarse/ner.pickle"

coarse_test_doc="common_data/nlp/test/coarse/doc.pickle"
coarse_test_ner="common_data/nlp/test/coarse/ner.pickle"

# keys to keep separated NLP tags for particular coarse class (6-main categories)
abbr_training_doc="common_data/nlp/training/fine/abbr_doc.pickle"
desc_training_doc="common_data/nlp/training/fine/desc_doc.pickle"
enty_training_doc="common_data/nlp/training/fine/enty_doc.pickle"
hum_training_doc="common_data/nlp/training/fine/hum_doc.pickle"
loc_training_doc="common_data/nlp/training/fine/loc_doc.pickle"
num_training_doc="common_data/nlp/training/fine/num_doc.pickle"

abbr_training_ner="common_data/nlp/training/fine/abbr_ner.pickle"
desc_training_ner="common_data/nlp/training/fine/desc_ner.pickle"
enty_training_ner="common_data/nlp/training/fine/enty_ner.pickle"
hum_training_ner="common_data/nlp/training/fine/hum_ner.pickle"
loc_training_ner="common_data/nlp/training/fine/loc_ner.pickle"
num_training_ner="common_data/nlp/training/fine/num_ner.pickle"

abbr_test_doc="common_data/nlp/test/fine/abbr_doc.pickle"
desc_test_doc="common_data/nlp/test/fine/desc_doc.pickle"
enty_test_doc="common_data/nlp/test/fine/enty_doc.pickle"
hum_test_doc="common_data/nlp/test/fine/hum_doc.pickle"
loc_test_doc="common_data/nlp/test/fine/loc_doc.pickle"
num_test_doc="common_data/nlp/test/fine/num_doc.pickle"

abbr_test_ner="common_data/nlp/test/fine/abbr_ner.pickle"
desc_test_ner="common_data/nlp/test/fine/desc_ner.pickle"
enty_test_ner="common_data/nlp/test/fine/enty_ner.pickle"
hum_test_ner="common_data/nlp/test/fine/hum_ner.pickle"
loc_test_ner="common_data/nlp/test/fine/loc_ner.pickle"
num_test_ner="common_data/nlp/test/fine/num_ner.pickle"

# keys to save dataprep and ML Algorithms models
coarse_word_vec="vectorizers/coarse_word_vec.pickle"
coarse_lemma_vec="vectorizers/coarse_lemma_vec.pickle"
coarse_pos_vec="vectorizers/coarse_pos_vec.pickle"
coarse_tag_vec="vectorizers/coarse_tag_vec.pickle"
coarse_dep_vec="vectorizers/coarse_dep_vec.pickle"
coarse_shape_vec="vectorizers/coarse_shape_vec.pickle"
coarse_alpha_vec="vectorizers/coarse_alpha_vec.pickle"
coarse_stop_vec="vectorizers/coarse_stop_vec.pickle"
coarse_ner_vec="vectorizers/coarse_ner_vec.pickle"

abbr_word_vec="vectorizers/abbr_word_vec.pickle"
abbr_lemma_vec="vectorizers/abbr_lemma_vec.pickle"
abbr_pos_vec="vectorizers/abbr_pos_vec.pickle"
abbr_tag_vec="vectorizers/abbr_tag_vec.pickle"
abbr_dep_vec="vectorizers/abbr_dep_vec.pickle"
abbr_shape_vec="vectorizers/abbr_shape_vec.pickle"
abbr_alpha_vec="vectorizers/abbr_alpha_vec.pickle"
abbr_stop_vec="vectorizers/abbr_stop_vec.pickle"
abbr_ner_vec="vectorizers/abbr_ner_vec.pickle"

desc_word_vec="vectorizers/desc_word_vec.pickle"
desc_lemma_vec="vectorizers/desc_lemma_vec.pickle"
desc_pos_vec="vectorizers/desc_pos_vec.pickle"
desc_tag_vec="vectorizers/desc_tag_vec.pickle"
desc_dep_vec="vectorizers/desc_dep_vec.pickle"
desc_shape_vec="vectorizers/desc_shape_vec.pickle"
desc_alpha_vec="vectorizers/desc_alpha_vec.pickle"
desc_stop_vec="vectorizers/desc_stop_vec.pickle"
desc_ner_vec="vectorizers/desc_ner_vec.pickle"

enty_word_vec="vectorizers/enty_word_vec.pickle"
enty_lemma_vec="vectorizers/enty_lemma_vec.pickle"
enty_pos_vec="vectorizers/enty_pos_vec.pickle"
enty_tag_vec="vectorizers/enty_tag_vec.pickle"
enty_dep_vec="vectorizers/enty_dep_vec.pickle"
enty_shape_vec="vectorizers/enty_shape_vec.pickle"
enty_alpha_vec="vectorizers/enty_alpha_vec.pickle"
enty_stop_vec="vectorizers/enty_stop_vec.pickle"
enty_ner_vec="vectorizers/enty_ner_vec.pickle"

hum_word_vec="vectorizers/hum_word_vec.pickle"
hum_lemma_vec="vectorizers/hum_lemma_vec.pickle"
hum_pos_vec="vectorizers/hum_pos_vec.pickle"
hum_tag_vec="vectorizers/hum_tag_vec.pickle"
hum_dep_vec="vectorizers/hum_dep_vec.pickle"
hum_shape_vec="vectorizers/hum_shape_vec.pickle"
hum_alpha_vec="vectorizers/hum_alpha_vec.pickle"
hum_stop_vec="vectorizers/hum_stop_vec.pickle"
hum_ner_vec="vectorizers/hum_ner_vec.pickle"

loc_word_vec="vectorizers/loc_word_vec.pickle"
loc_lemma_vec="vectorizers/loc_lemma_vec.pickle"
loc_pos_vec="vectorizers/loc_pos_vec.pickle"
loc_tag_vec="vectorizers/loc_tag_vec.pickle"
loc_dep_vec="vectorizers/loc_dep_vec.pickle"
loc_shape_vec="vectorizers/loc_shape_vec.pickle"
loc_alpha_vec="vectorizers/loc_alpha_vec.pickle"
loc_stop_vec="vectorizers/loc_stop_vec.pickle"
loc_ner_vec="vectorizers/loc_ner_vec.pickle"

num_word_vec="vectorizers/num_word_vec.pickle"
num_lemma_vec="vectorizers/num_lemma_vec.pickle"
num_pos_vec="vectorizers/num_pos_vec.pickle"
num_tag_vec="vectorizers/num_tag_vec.pickle"
num_dep_vec="vectorizers/num_dep_vec.pickle"
num_shape_vec="vectorizers/num_shape_vec.pickle"
num_alpha_vec="vectorizers/num_alpha_vec.pickle"
num_stop_vec="vectorizers/num_stop_vec.pickle"
num_ner_vec="vectorizers/num_ner_vec.pickle"

coarse_model="models/coarse_model.pickle"
abbr_model="models/abbr_model.pickle"
desc_model="models/desc_model.pickle"
enty_model="models/enty_model.pickle"
hum_model="models/hum_model.pickle"
loc_model="models/loc_model.pickle"
num_model="models/num_model.pickle"

# Neural Network additional objects required
label_binarizer="binarizer/label_binarizer.pickle"